[{"content":"This article offers a sample of basic Markdown formatting that can be used in Congo, also it shows how some basic HTML elements are decorated.\nHeadings #The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 #H2 #H3 #H4 #H5 #H6 #Paragraph #Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes #The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution # Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution # Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables #Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables # Italics Bold Code italics bold code Code Blocks #Code block with backticks #\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces #\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode # 1 2 3 4 5 6 7 8 9 10 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types #Ordered List # First item Second item Third item Unordered List # List item Another item And another item Nested list # Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark #GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk about nothing during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024年2月18日","permalink":"/ja/posts/post/","section":"ブログ投稿","summary":"\u003cp\u003eThis article offers a sample of basic Markdown formatting that can be used in Congo, also it shows how some basic HTML elements are decorated.\u003c/p\u003e","title":"First post"},{"content":"","date":null,"permalink":"/ja/tags/katex/","section":"Tags","summary":"","title":"katex"},{"content":"","date":null,"permalink":"/ja/tags/maths/","section":"Tags","summary":"","title":"maths"},{"content":"","date":null,"permalink":"/ja/tags/sample/","section":"Tags","summary":"","title":"sample"},{"content":"","date":null,"permalink":"/ja/tags/shortcodes/","section":"Tags","summary":"","title":"shortcodes"},{"content":"CongoはHugoのTaxonomiesを完全にサポートしており、どのようなTaxonomiesの設定にも適応します。Taxonomiesのリストは、用語リストの上に表示されるカスタムコンテンツもサポートしています。\nこの領域は各Taxonomyに説明的なテキストを追加するために使用することができます。このコンセプトをさらに発展させる方法について、以下の Tags/advancedも参照してください。\n","date":null,"permalink":"/ja/tags/","section":"Tags","summary":"CongoはHugoのTaxonomiesを完全にサポートしており、どのようなTaxonomiesの設定にも適応します。Taxonomiesのリストは、用語リストの上に表示されるカスタムコンテンツもサポートしています。","title":"Tags"},{"content":"Welcome to my website! I\u0026rsquo;m really happy you stopped by.\n","date":null,"permalink":"/ja/","section":"Welcome to Congo!","summary":"Welcome to my website!","title":"Welcome to Congo!"},{"content":" Daily blog posts will be updated. 💻 ","date":null,"permalink":"/ja/posts/","section":"ブログ投稿","summary":"Daily blog posts will be updated.","title":"ブログ投稿"},{"content":"","date":null,"permalink":"/ja/tags/python/","section":"Tags","summary":"","title":"python"},{"content":"","date":null,"permalink":"/ja/tags/scipy/","section":"Tags","summary":"","title":"scipy"},{"content":"","date":null,"permalink":"/ja/tags/ttest_rel/","section":"Tags","summary":"","title":"ttest_rel"},{"content":"","date":null,"permalink":"/ja/tags/%E5%AF%BE%E5%BF%9C%E3%81%AE%E3%81%82%E3%82%8Bt%E6%A4%9C%E5%AE%9A/","section":"Tags","summary":"","title":"対応のあるt検定"},{"content":"","date":null,"permalink":"/ja/tags/%E7%B5%B1%E8%A8%88/","section":"Tags","summary":"","title":"統計"},{"content":"この投稿は、統計学で使用される対応のあるt検定について説明するために書かれました。\n今回もPythonライブラリScipyを利用して対応のあるt検定を行います。\n対応のあるt検定 #対応のあるt検定は、2つの関連するグループ間の平均を比較する統計的技術です。この方法は、通常、同一の被験者グループに対して2つの測定値がある場合に適用されます。対応のあるt検定は、2つの関連するグループ間の平均の差が統計的に有意かどうかを判断するために使用されます。\n1. 仮説設定 # H₀ : 𝜇D = 0 → 帰無仮説 (𝜇𝐷 = 𝜇₁ - 𝜇₂) 実験前後の平均の差は0です。 H₁ : 𝜇D ≠ 0 → 対立仮説 実験前後の平均の差は0ではありません。 2. 正規性検定 #2つのグループのサンプル数が30未満の場合、正規性検定を行う必要があります。\n2つのグループのサンプル数が30以上の場合、中心極限定理により正規性が満たされたと仮定します。\nScipyでの正規性検定はShapiro-Wilk検定を通じて確認可能です。 4. 対応のあるt検定統計量の計算 #2つのグループの平均と標準偏差を使用して、対応のあるt検定統計量を計算します。\n5. 決定/結論 #計算されたT統計量が臨界値を超えた場合、帰無仮説を棄却し、対立仮説を採用します。\nそうでない場合、帰無仮説を棄却しません。\n統計的に有意な差がある場合、2つのグループ間に平均の差が存在すると結論付けます。\nPythonライブラリScipyの利用方法 #以下はPythonのScipyライブラリを利用して対応のあるt検定を行う方法です。\n今回扱うデータには、Aのクラスでは筋トレが集中力を向上させるという話があり、Aが実際に筋トレを始める前と後で比較することにしました。Aは20人に筋トレを行わせた後、トレーニング前と後で集中力測定テストを受けさせた結果です。\n筋トレ前後で集中力に有意な差があるかどうかを対応のあるt検定を通じて調べたいと思います。\n仮説は以下の通りです。\n帰無仮説 : 筋トレ前後のテスト平均は同じです。\n対立仮説 : 筋トレ前後のテスト平均は同じではありません。\n有意水準は0.05に設定します。\nまずはデータを読み込みましょう。\n\u0026gt;\u0026gt;\u0026gt; import pandas as pd \u0026gt;\u0026gt;\u0026gt; from scipy import stats \u0026gt;\u0026gt;\u0026gt; df = pd.read_csv(\u0026#34;./data/ch11_training_rel.csv\u0026#34;) \u0026gt;\u0026gt;\u0026gt; df.head() 전 후 0 59 41 1 52 63 2 55 68 3 61 59 4 59 84 次に、正規性検定を行いましょう。\n\u0026gt;\u0026gt;\u0026gt; a = stats.shapiro(df[\u0026#39;前\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; b = stats.shapiro(df[\u0026#39;後\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; print(a, b) ShapiroResult(statistic=0.9670045375823975, pvalue=0.690794825553894) ShapiroResult(statistic=0.9786625504493713, pvalue=0.9156817197799683) 結果はどちらもp値が0.05より大きく、正規性が満たされています。\n次に、Scipyライブラリ内のttest_relを使ってt統計量とp値を求めます。\n\u0026gt;\u0026gt;\u0026gt; t_score, p_value = stats.ttest_rel(df[\u0026#39;前\u0026#39;], df[\u0026#39;後\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; print(round(t_score, 4), round(p_value, 2)) -2.2042 0.04 p値が有意水準0.05より小さいため、帰無仮説(筋トレ前後の平均が同じである)が棄却されました。したがって、筋トレ前後の平均スコアには有意な差があると言えます。\n","date":"2024年1月19日","permalink":"/ja/posts/10/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は、統計学で使用される対応のあるt検定について説明するために書かれました。\u003c/p\u003e","title":"統計 - 対応のあるt検定"},{"content":"","date":null,"permalink":"/ja/tags/ttest_ind/","section":"Tags","summary":"","title":"ttest_ind"},{"content":"この投稿は、統計学で使用される独立標本 t検定について説明するために書かれました。\n今回もPythonライブラリScipyを利用して独立標本t検定を行います。\n独立標本t検定 #独立標本t検定は、2つの独立した標本間の平均の差が統計的に有意かどうかを検定する統計分析技術です。これは、2つのグループ間の平均差が偶然に起こったものなのか、それとも実際に存在するものなのかを判断するために使用されます。\n独立標本 t検定の主要なステップは次のとおりです。\n1. 仮説の設定 # H₀ : 𝜇₁ = 𝜇₂ → 帰無仮説 2つのグループの平均は同じである。 H₁ : 𝜇₁ ≠ 𝜇₂ → 対立仮説 2つのグループの平均は異なる。 2. 正規性の検定 #2つのグループの標本数が30未満の場合、正規性の検定が必要です。\n2つのグループの標本数が30以上の場合、中心極限定理により正規性が満たされると仮定します。\nScipyでの正規性検定はShapiro-Wilk検定を通じて確認可能です。 3. 等分散性の検定 #2つのグループのデータ数が同じ場合、分散は等しいと仮定します。\n2つのグループのデータ数が異なる場合、分散が等しいかどうかを確認するために等分散性の検定を行うことができます。\nScipyでの等分散性検定はLevene検定を通じて確認可能です。 4. 独立標本 t統計量の計算 #2つのグループの平均と標準偏差を使用して独立標本 t統計量を計算します。\n5. 決定/結論 #計算されたt統計量が臨界値を超えた場合、帰無仮説を棄却し対立仮説を採用します。\nそうでない場合は、帰無仮説を棄却しません。\n統計的に有意な差がある場合、2つのグループ間に平均の差が存在すると結論付けます。\n独立標本t検定は、2つのグループ間の平均の差を比較するのに有用であり、実験群と対照群間の差を調査したり、2つの条件間の効果を確認するなどの状況で適用できます。\nPythonライブラリScipyの利用方法 #次に、PythonのScipyライブラリを利用して独立標本 t検定を行います。\n今回扱うデータには、人文系の学生が多いAクラスでは筋力トレーニングをする学生が急増し、Aはもし筋力トレーニングが集中力を向上させる効果があるなら、自分のクラスと通常から筋力トレーニングをしている体育系の学生が多いBクラスとの間に集中力テストの平均に差が出ないかと考え、Bクラスにも集中力テストを受けさせた結果です。\nAとBのクラスの集中力に有意な差があるかどうかを独立標本 t検定を通じて調べたいと思います。\n仮説は以下の通りです。\n帰無仮説 : AとBのクラスの平均は同じである。\n対立仮説 : AとBのクラスの平均は同じではない。\n有意水準は0.05に設定します。\nまず、データを読み込みましょう。\n\u0026gt;\u0026gt;\u0026gt; import pandas as pd \u0026gt;\u0026gt;\u0026gt; from scipy import stats \u0026gt;\u0026gt;\u0026gt; df = pd.read_csv(\u0026#34;./data/ch11_training_ind.csv\u0026#34;) \u0026gt;\u0026gt;\u0026gt; df.head() A B 0 47 49 1 50 52 2 37 54 3 60 48 4 39 51 次に、正規性検定を行います。\n\u0026gt;\u0026gt;\u0026gt; a = stats.shapiro(df[\u0026#39;A\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; b = stats.shapiro(df[\u0026#39;B\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; print(a, b) ShapiroResult(statistic=0.9685943722724915, pvalue=0.7249553203582764) ShapiroResult(statistic=0.9730021357536316, pvalue=0.8165789842605591) 結果は、どちらもp値が0.05より大きいので正規性が満たされています。\n次に、このデータはデータの個数が同じなので等分散と仮定しますが、各グループのデータ数が異なる場合は分散が等しいかを検定する必要があるため、Levene検定を通じて以下のように確認できます。\n\u0026gt;\u0026gt;\u0026gt; stats.levene(df[\u0026#39;A\u0026#39;], df[\u0026#39;B\u0026#39;]) LeveneResult(statistic=2.061573118077718, pvalue=0.15923550057222613) p値が0.159なので帰無仮説(2つのグループの分散に差がない)が採用されます。\n次に、Scipyライブラリ内の ttest_indを使用してt統計量とp値を求めます。\n\u0026gt;\u0026gt;\u0026gt; t, p = stats.ttest_ind(df[\u0026#39;A\u0026#39;], df[\u0026#39;B\u0026#39;], equal_var=False) # equal_var=False: Welchの方法 \u0026gt;\u0026gt;\u0026gt; t, p (-1.760815724652471, 0.08695731107259362) p値が有意水準0.05より大きいため、帰無仮説（AとBのクラスの平均が同じである）が採用されました。したがって、AのクラスとBのクラスの間には平均スコアに有意な差があるとは言えません。\n","date":"2024年1月15日","permalink":"/ja/posts/9/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は、統計学で使用される独立標本 t検定について説明するために書かれました。\u003c/p\u003e","title":"統計 - 独立標本t検定"},{"content":"","date":null,"permalink":"/ja/tags/%E7%8B%AC%E7%AB%8B%E6%A8%99%E6%9C%AC-t%E6%A4%9C%E5%AE%9A/","section":"Tags","summary":"","title":"独立標本 t検定"},{"content":"","date":null,"permalink":"/ja/tags/1%E6%A8%99%E6%9C%AC%E3%81%AEt%E6%A4%9C%E5%AE%9A/","section":"Tags","summary":"","title":"1標本のt検定"},{"content":"この投稿は、統計学で使用される1標本のt検定について説明するために作成されました。\nさらに、PythonのScipyライブラリを利用して単一標本 T検定を行います。\n1標本のt検定とは？ #1標本のt検定　は、統計分析で使用される仮説検定の方法の一つで、一つの標本に対する平均を検定するのに使用されます。主に母集団の平均が特定の値と同じかどうかを確認したい場合に適用されます。\n1標本のt検定は次のような手順で行われます。\n1. 仮説の設定 # H₀ : 𝜇 = 𝜇₀ → 帰無仮説 母平均と標本平均は同じである。 H₁ : 𝜇 ≠ 𝜇₀ → 対立仮説 母平均と標本平均は同じではない。 2. 標本の抽出 #母集団から標本を抽出し、その標本の平均を計算します。\n3. 仮説検定の統計量の計算 #t-統計量を計算します。これは、標本平均と仮説に基づく期待平均間の差を示します。\n4. 決定/結論 #計算されたt-統計量が棄却域に入る場合、帰無仮説を棄却し、対立仮説を採用します。\nそうでない場合は、帰無仮説を棄却しません。\n両側検定の場合、棄却域はt分布の両端に対称的な部分です。 帰無仮説を棄却した場合、標本が母集団と異なると結論付けます。\n逆に棄却できなかった場合、統計的に有意ではないと結論付けます。\nPythonライブラリScipyの利用方法 #次に、PythonのScipyライブラリを利用して単一標本 T検定を行います。\n今回扱うデータには、31本の木の周囲長、高さ、体積が記録されています。\nこの標本の平均が母平均と一致するかどうかを単一標本 T検定で調べたいと思います。仮説は以下のとおりです。\n有意水準は0.05に設定します。\n仮説検定\n帰無仮説 : 平均は75である。\n対立仮説 : 平均は75ではない。\nまず、データを読み込みます。\n\u0026gt;\u0026gt;\u0026gt; import pandas as pd \u0026gt;\u0026gt;\u0026gt; df = pd.read_csv(\u0026#34;./data/trees.csv\u0026#34;) \u0026gt;\u0026gt;\u0026gt; df.head() Girth Height Volume 0 8.3 70 10.3 1 8.6 65 10.3 2 8.8 63 10.2 3 10.5 72 16.4 4 10.7 81 18.8 また、標本平均「Height」の平均を計算しましょう。\n\u0026gt;\u0026gt;\u0026gt; result = df[\u0026#39;Height\u0026#39;].mean() \u0026gt;\u0026gt;\u0026gt; round(result, 2) # (小数点第2位まで四捨五入して計算) 76.0 次に、1標本のt検定のためにScipyライブラリを読み込みます。\n\u0026gt;\u0026gt;\u0026gt; from scipy import stats 単一標本 T検定にはScipy内の ttest_1samp　を使用して検定します。 参照　: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html\n次に、仮説検定の統計量を計算しましょう。\n\u0026gt;\u0026gt;\u0026gt; from math import sqrt \u0026gt;\u0026gt;\u0026gt; t_score, p_value = stats.ttest_1samp(df[\u0026#39;Height\u0026#39;], popmean=75) \u0026gt;\u0026gt;\u0026gt; print(round(t_score, 2), round(p_value, 2)) 0.87 0.39 popmeanは帰無仮説で予想された平均と同じです。\n上記の統計量に対するp値を計算した後（小数点第4位まで四捨五入して計算）、有意水準0.05での仮説検定の結果、帰無仮説を棄却するかどうかを確認しましょう。\n\u0026gt;\u0026gt;\u0026gt; print(round(p_value, 4)) 0.3892 \u0026gt;\u0026gt;\u0026gt; if p_value \u0026gt;= 0.05: print(\u0026#34;Accept\u0026#34;) else: print(\u0026#34;Reject\u0026#34;) Accept したがって、標本平均は母平均と同じであるという帰無仮説を棄却できませんでした。\n","date":"2024年1月13日","permalink":"/ja/posts/8/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は、統計学で使用される1標本のt検定について説明するために作成されました。\u003c/p\u003e","title":"統計 - 1標本のt検定"},{"content":"","date":null,"permalink":"/ja/tags/%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90/","section":"Tags","summary":"","title":"回帰分析"},{"content":"この投稿は統計学における回帰分析について説明するために作成されました。\n回帰分析とは？ #回帰分析とは、一つまたはそれ以上の独立変数が従属変数に与える影響を推定できる統計技術を指します。\n回帰分析の変数 #従属変数(Dependent Variable) yは影響を受ける変数で、応答変数(Response Variable)、結果変数(Outcome Variable)とも呼ばれます。モデルで予測しようとする変数であり、従属変数は他の変数によって影響を受けます。\n独立変数(Independent Variable) xは影響を与える変数で、説明変数(Explanatory Variable)、予測変数(Predictor Variable)とも呼ばれます。独立変数は従属変数に影響を与える変数であり、予測モデルを構築する際に使用されます。\n変数の数による回帰分析方法 #回帰分析は変数の数に応じてアプローチ方法が異なります。独立変数の数が一つならば単純線形回帰分析で、独立変数の数が二つ以上ならば多重線形回帰分析アプローチが可能です。\n1. 単純線形回帰分析(Simple Linear Regression) #一つの独立変数が従属変数に与える影響を推定できる統計技術を指します。予測値と実際のデータの誤差(=残差)が最も小さい直線を回帰直線として選びます。回帰直線は数多くの直線の中から、データに対して 残差平方和(Residual Sum of Squares, RSS) がより小さい直線を意味します。\nこれは 最小二乗法(Ordinary Least Square) を通じて行われます。\n最小二乗法 #測定値を基に平方和を作り、それが最小となる値を求めて処理する方法、残差平方和が最も小さい線を選びます。\n2. 多重線形回帰分析(Multiple Linear Regression) #二つ以上の独立変数が一つの従属変数に与える影響を推定する統計技術を指します。多重線形回帰分析では 回帰係数の有意性を判断することが重要です。なぜなら、選択された変数の組み合わせでモデルを確認できるように、すべての回帰係数の有意性が統計的に検証される必要があるからです。\n回帰係数の有意性は単純回帰分析の回帰係数有意性検討と同様に 回帰係数 t-統計量 を通じて確認が可能です。\n多重共線性(Multicollinearity) #多重共線性は回帰分析で独立変数間に強い相関関係が現れる現象を意味します。つまり、一つの独立変数を他の独立変数で予測できる場合に発生します。\n多重共線性が発生すると、各独立変数の回帰係数の正確な推定が困難になります。また、各独立変数の回帰係数が従属変数に与える影響力を正しく説明できなくなります。\n多重共線性をチェックする方法\n分散拡大係数 (VIF, Variance Inflation Factor):\n分散拡大係数は、各独立変数の分散がどれだけ増加したかを示し、この値が大きいと多重共線性が増加したと判断します。これは各独立変数を他の独立変数で線形回帰した結果の分散比率で計算されます。一般的に、分散拡大係数が 4以上であれば 多重共線性が存在する と判断され、 10以上であれば 重大な問題がある と解釈されます。\n回帰分析時の検討事項 #回帰分析を実施する場合、検討すべき事項は以下の三つの項目があります。\n1. 回帰係数は有意性 #該当係数の t-統計量のp値が　0.05より小さければ該当回帰係数が統計的に有意であると判断します。つまり、係数が従属変数に対して　有意な影響を与える　ことを意味します。\n2. モデルはどれくらい説明力を持つか？ #モデルがどれくらい説明力を持つか確認するためには　決定係数(𝑅²) を確認する必要があります。\n決定係数(Coefficient of Determination; 𝑅²) #決定係数は0から1の間の値で、1に近いほどモデルが従属変数の変動をよく説明していることを意味します。変動をよく説明するとは、回帰線にどれだけ変動があるか確認が可能であるという意味です。\n高い決定係数はモデルの予測能力が高いことを示します。\n3. モデルはデータによく適合しているか？ #モデルがデータによく適合しているかを判断するためには、残差をグラフに描き回帰診断を行います。残差は実際の値とモデルの予測値との差を意味し、これを視覚的に検討してモデルがデータにどれくらいよく適合しているかを確認します。一般的に、残差は正規分布に従い、特定のパターンや傾向がないことが望ましいです。また、残差の等分散性も確認される必要があります。異常値や影響力のあるデータポイントがあるかも検討し、必要に応じてこれを除去または調整してモデルの安定性を確認します。\nこれらの検討を通じて、回帰分析の信頼性とモデルの適合性を評価することができます。\n","date":"2024年1月12日","permalink":"/ja/posts/7/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は統計学における回帰分析について説明するために作成されました。\u003c/p\u003e","title":"統計 - 回帰分析"},{"content":"","date":null,"permalink":"/ja/tags/%E4%BB%AE%E8%AA%AC%E6%A4%9C%E5%AE%9A/","section":"Tags","summary":"","title":"仮説検定"},{"content":"","date":null,"permalink":"/ja/tags/%E5%B8%B0%E7%84%A1%E4%BB%AE%E8%AA%AC/","section":"Tags","summary":"","title":"帰無仮説"},{"content":"","date":null,"permalink":"/ja/tags/%E5%AF%BE%E7%AB%8B%E4%BB%AE%E8%AA%AC/","section":"Tags","summary":"","title":"対立仮説"},{"content":"この投稿は、pandasライブラリを活用して複数のデータを一つに統合する方法について説明するために作成されました。\n統計学での仮説(Hypothesis)は、ある主張や推測を示す命題であり、母数に関する仮定/暫定的結論を意味します。\n仮説の種類 #仮説は以下のように二つの形式で表されます。\n1. 帰無仮説 (Null Hypothesis, H0) #帰無仮説は、元の比較対象として変化や差がないことを示す仮説であり、ある種のデフォルトの仮説です。\n検定方法によって帰無仮説の内容は異なります。例えば、「二つのグループの平均は同じである」という主張が帰無仮説として設定されることがあります。\n2. 対立仮説 (Alternative Hypothesis, H1) #対立仮説は、 帰無仮説に対立する主張であり、標本を通じて確実な根拠を持って証明しようとする仮説です。例えば、「二つのグループの平均は異なる」という主張が対立仮説として設定されることがあります。\n統計的検定を通じて与えられたデータを使用して帰無仮説を棄却するか、または棄却する根拠がないために帰無仮説を棄却できないと決定します。検定結果で対立仮説が真である確実な根拠を発見した場合、帰無仮説を棄却します。\n統計学で主張したいこのような仮説の妥当性を検証するプロセスがまさに仮説検定です。\n仮説検定 #1. 仮説の設定 #仮説検定の最初のステップは、調査したい問題に応じて帰無仮説(H0)と対立仮説(H1)を設定することです。\n2. 標本分析 #次に、全体母集団から一部を代表することができる標本を抽出します。この標本についてデータを収集し分析します。これにより、統計的分析に使用する資料を確保します。\n3. 仮説の妥当性検証 #収集したデータを使用して仮説を検証します。統計的手法を利用して帰無仮説を棄却するか、または棄却する根拠がないために帰無仮説を採用するかを決定します。これは有意水準と検定統計量を考慮して行われます。\n有意水準 (Level of Significance)\n有意水準は、主にα(alpha)で表され、実験または調査で帰無仮説を棄却する基準確率を示します。\n一般的に使用される有意水準は0.05(5%)ですが、実験の性質や研究の特性に応じて0.01や0.10など他の値を使用することがあります。\n検定統計量\n検定統計量は、収集したデータと仮説がどの程度一致するかを測る指標であり、母数推定をするために必要な標本統計量です。検定統計量は仮説検定で重要な役割を果たし、帰無仮説の棄却の有無を決定するために使用されます。\n仮説を検定する過程で、統計的な誤りが生じる可能性が常に存在し、これを仮説検定誤라고 합니다.\n統計的過誤 #1. 第一種過誤 #第一種過誤は、帰無仮説が真のときに帰無仮説を棄却する誤りを指します。第一種の誤りが発生する原因は、統計的検定で有意水準(significance level)を設定することにあり、この水準で帰無仮説を棄却するときに偶然に生じます。\n例) 実際には効果がないのに、効果があると誤って結論づける状況\n2. 第二種過誤 #第二種過誤は、対立仮説が真のときに帰無仮説を採用する誤りを指します。第二種の誤りが発生する原因は、検定力(power)が不足して実際に存在する効果を感知できないときに生じます。\n例) 実際には効果があるのに、統計的検定でその効果を見つけられずに帰無仮説を採用する状況\n","date":"2024年1月11日","permalink":"/ja/posts/6/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は、pandasライブラリを活用して複数のデータを一つに統合する方法について説明するために作成されました。\u003c/p\u003e","title":"統計 - 仮説検定 (1)"},{"content":"","date":null,"permalink":"/ja/tags/concat/","section":"Tags","summary":"","title":"concat"},{"content":"","date":null,"permalink":"/ja/tags/join/","section":"Tags","summary":"","title":"join"},{"content":"","date":null,"permalink":"/ja/tags/merge/","section":"Tags","summary":"","title":"merge"},{"content":"","date":null,"permalink":"/ja/tags/pandas/","section":"Tags","summary":"","title":"pandas"},{"content":"この投稿は、pandasライブラリを活用して複数のデータを一つに統合する方法について説明するために作成されました。\nデータを統合する方法にはいくつかありますが、今回扱うのは concat, join, mergeです。\n説明する前に、例として2つのデータフレームを作成しましょう。\n\u0026gt;\u0026gt;\u0026gt; import pandas as pd \u0026gt;\u0026gt;\u0026gt; df1 = pd.DataFrame({ \u0026#39;Class1\u0026#39; : [95, 92, 98, 100], \u0026#39;Class2\u0026#39; : [91, 93, 97, 99] }) \u0026gt;\u0026gt;\u0026gt; df2 = pd.DataFrame({ \u0026#39;Class1\u0026#39; : [87, 89], \u0026#39;Class2\u0026#39; : [85, 90] }) d1の出力値:\nClass1 Class2 0 87 85 1 89 90 d2の出力値:\nClass1 Class2 0 95 91 1 92 93 2 98 97 3 100 99 1. concat #pandasライブラリの concat 関数はデータフレームを連結するために使用されます。この関数は複数のデータフレームを行または列方向に連結することができます。\ndf1とdf2をresultに連結しましょう。\n\u0026gt;\u0026gt;\u0026gt; result = pd.concat([df1, df2]) \u0026gt;\u0026gt;\u0026gt; result Class1 Class2 0 95 91.0 1 92 93.0 2 98 97.0 3 100 99.0 4 87 85.0 5 89 90.0 6 96 NaN 7 83 NaN **pd.concat([df1, df2])**は df1と df2を行の方向に連結します。つまり、2つのデータフレームが上下に接続されます。\n次に、Class1列のみを持つd3をresultに統合しましょう。\n\u0026gt;\u0026gt;\u0026gt; df3 = pd.DataFrame({ \u0026#39;Class1\u0026#39; : [96, 83] }) \u0026gt;\u0026gt;\u0026gt; pd.concat([result, df3], ignore_index=True) Class1 Class2 0 95 91.0 1 92 93.0 2 98 97.0 3 100 99.0 4 87 85.0 5 89 90.0 6 96 NaN 7 83 NaN d3データは\u0026rsquo;Class2\u0026rsquo;列を持っていないため、空白値が出力されます。\n2. join #pandasライブラリのj join メソッドは、2つのデータフレームを特定の列を基準に結合するために使用されます。一般的にSQLの JOIN 操作と同様の役割を果たします。 concatとは異なり、 joinは横方向に統合されます。\n\u0026gt;\u0026gt;\u0026gt; df4 = pd.DataFrame({ \u0026#39;Class3\u0026#39; : [93, 91, 95, 98] }) \u0026gt;\u0026gt;\u0026gt; df1.join(df4) Class1 Class2 Class3 a 95 91 93 b 92 93 91 c 98 97 95 d 100 99 98 次のようにインデックスを任意に設定して出力することも可能です。\n\u0026gt;\u0026gt;\u0026gt; index_label = [\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;] \u0026gt;\u0026gt;\u0026gt; df1a = pd.DataFrame({\u0026#39;Class1\u0026#39;: [95, 92, 98, 100], \u0026#39;Class2\u0026#39;: [91, 93, 97, 99]}, index= index_label) \u0026gt;\u0026gt;\u0026gt; df4a = pd.DataFrame({\u0026#39;Class3\u0026#39;: [93, 91, 95, 98]}, index=index_label) \u0026gt;\u0026gt;\u0026gt; df1a.join(df4a) Class1 Class2 Class3 a 95 91 93 b 92 93 91 c 98 97 95 d 100 99 98 3. merge #pandasライブラリのmerge関数は、2つのデータフレームを特定の列を基準にマージ（統合）するために使用されます。merge関数を使用すると、データフレーム間で共通の列を基準に結合することができます。\n\u0026gt;\u0026gt;\u0026gt; df_A_B = pd.DataFrame({\u0026#39;販売月\u0026#39;: [\u0026#39;1月\u0026#39;, \u0026#39;2月\u0026#39;, \u0026#39;3月\u0026#39;, \u0026#39;4月\u0026#39;], \u0026#39;製品A\u0026#39;: [100, 150, 200, 130], \u0026#39;製品B\u0026#39;: [90, 110, 140, 170]}) \u0026gt;\u0026gt;\u0026gt; df_C_D = pd.DataFrame({\u0026#39;販売月\u0026#39;: [\u0026#39;1月\u0026#39;, \u0026#39;2月\u0026#39;, \u0026#39;3月\u0026#39;, \u0026#39;4月\u0026#39;], \u0026#39;製品C\u0026#39;: [112, 141, 203, 134], \u0026#39;製品D\u0026#39;: [90, 110, 140, 170]}) df_A_B\n販売月 製品A 製品B 0 1月 100 90 1 2月 150 110 2 3月 200 140 3 4月 130 170 df_C_D\n販売月 製品C 製品D 0 1月 112 90 1 2月 141 110 2 3月 203 140 3 4月 134 170 mergeを使って　*\u0026lsquo;販売月\u0026rsquo;*列を基準に2つのデータフレームをマージします。結果として \u0026lsquo;販売月\u0026rsquo; 列を基準に2つのデータフレームが結合され、共通の列を中心にデータが整理されます。\n\u0026gt;\u0026gt;\u0026gt; df_A_B.merge(df_C_D) 販売月 製品A 製品B 製品C 製品D 0 1月 100 90 112 90 1 2月 150 110 141 110 2 3月 200 140 203 140 3 4月 130 170 134 170 mergeメソッドを使用して2つのデータフレームを結合する4つの異なる方法を実装してみましょう。\n\u0026gt;\u0026gt;\u0026gt; df_left = pd.DataFrame({\u0026#39;key\u0026#39;:[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;left\u0026#39;: [1, 2, 3]}) \u0026gt;\u0026gt;\u0026gt; df_right = pd.DataFrame({\u0026#39;key\u0026#39;:[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;right\u0026#39;: [4, 5, 6]}) 1.\n\u0026gt;\u0026gt;\u0026gt; df_left.merge(df_right, how=\u0026#39;left\u0026#39;, on = \u0026#39;key\u0026#39;) key left right 0 A 1 4.0 1 B 2 5.0 2 C 3 NaN \u0026lsquo;key\u0026rsquo;列を基準にdf_leftとdf_rightを左結合（left join）します。左結合は左データフレーム(df_left)の全ての行を保持し、右データフレーム(df_right)の該当するキー値がある行を追加します。該当するキー値が右データフレームにない場合はNaNで埋められます。\n2.\n\u0026gt;\u0026gt;\u0026gt; df_left.merge(df_right, how=\u0026#39;right\u0026#39;, on = \u0026#39;key\u0026#39;) key left right 0 A 1.0 4 1 B 2.0 5 2 D NaN 6 \u0026lsquo;key\u0026rsquo;列を基準にdf_leftとdf_rightを右結合（right join）します。右結合は右データフレーム(df_right)の全ての行を保持し、左データフレーム(df_left)の該当するキー値がある行を追加します。該当するキー値が左データフレームにない場合はNaNで埋められます。\n3.\n\u0026gt;\u0026gt;\u0026gt; df_left.merge(df_right, how=\u0026#39;outer\u0026#39;, on = \u0026#39;key\u0026#39;) key left right 0 A 1.0 4.0 1 B 2.0 5.0 2 D 3.0 NaN 3 D NaN 6.0 \u0026lsquo;key\u0026rsquo;列を基準にdf_leftとdf_rightを外部結合（outer join）します。外部結合は両方のデータフレームの全ての行を含み、一方のデータフレームにのみ該当する場合はNaNで埋められます。\n4.\n\u0026gt;\u0026gt;\u0026gt; df_left.merge(df_right, how=\u0026#39;inner\u0026#39;, on = \u0026#39;key\u0026#39;) key left right 0 A 1 4 1 B 2 5 \u0026lsquo;key\u0026rsquo;列を基準にdf_leftとdf_rightを内部結合（inner join）します。内部結合は両方のデータフレームに共通して存在する行のみを含みます。つまり、両方のデータフレームで同じ\u0026rsquo;key\u0026rsquo;値を持つ行を結合します。\n","date":"2024年1月8日","permalink":"/ja/posts/5/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は、pandasライブラリを活用して複数のデータを一つに統合する方法について説明するために作成されました。\u003c/p\u003e","title":"Python - pandasデータ統合 (concat, join, merge)"},{"content":"","date":null,"permalink":"/ja/tags/matplotlib/","section":"Tags","summary":"","title":"matplotlib"},{"content":"この記事は、Python内のmatplotlibライブラリを使用してグラフにテキストを追加する方法を説明するために作成されました。\nmatplotlibを活用してグラフを出力する際、以下のようにグラフ上にテキストを追加してみましょう。 まず、以下のように任意の月別売上数量のデータを持って実装しましょう。\n\u0026gt;\u0026gt;\u0026gt; import calendar \u0026gt;\u0026gt;\u0026gt; month_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] \u0026gt;\u0026gt;\u0026gt; sold_list = [300, 400, 550, 900, 600, 960, 900, 910, 800, 700, 550, 450] \u0026gt;\u0026gt;\u0026gt; fig, ax = plt.subplots() \u0026gt;\u0026gt;\u0026gt; barcharts = ax.bar(month_list, sold_list) # calendar.month_name[1:13] → xlabelに1月から12月まで出力 \u0026gt;\u0026gt;\u0026gt; ax.set_xticks(month_list, calendar.month_name[1:13], rotation=90) \u0026gt;\u0026gt;\u0026gt; print(barcharts) コードを実行すると、以下のようなグラフが出力されます。\n次に、各バー上に該当するy値を追加しましょう。\n各バーの値を得た後、テキストとして追加するためには、y値を出力するget_height()とバーにテキストを入力するax.text()を使用します。\n参照:\nget_height()\nhttps://matplotlib.org/stable/api/_as_gen/matplotlib.patches.Rectangle.html\nax.text()\nhttps://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html#matplotlib.axes.Axes.text\n完成したコードは以下の通りです。\n\u0026gt;\u0026gt;\u0026gt; import calendar \u0026gt;\u0026gt;\u0026gt; month_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] \u0026gt;\u0026gt;\u0026gt; sold_list = [300, 400, 550, 900, 600, 960, 900, 910, 800, 700, 550, 450] \u0026gt;\u0026gt;\u0026gt; fig, ax = plt.subplots() \u0026gt;\u0026gt;\u0026gt; barcharts = ax.bar(month_list, sold_list) \u0026gt;\u0026gt;\u0026gt; ax.set_xticks(month_list, calendar.month_name[1:13], rotation=90) \u0026gt;\u0026gt;\u0026gt; print(barcharts) \u0026gt;\u0026gt;\u0026gt; for rect in barcharts: height = rect.get_height() ax.text(rect.get_x() + rect.get_width()/2., 1.002*height,\u0026#39;%d\u0026#39; % int(height), ha=\u0026#39;center\u0026#39;, va=\u0026#39;bottom\u0026#39;) \u0026gt;\u0026gt;\u0026gt; plt.show() rect.get_x() + rect.get_width()/2.\n各バーのX位置と幅の中間点を計算します。これはバーの横軸中心を表します。\n1.002 * height\nheightは現在のバーの高さであり、1.002*heightはバーの高さよりも少し上にテキストを配置するための補正値です。\n\u0026rsquo;% d\u0026rsquo; % int(height)\n文字列フォーマッティング、つまり、各バーごとの高さ値を追加（%の後に来るd(整数)を追加、int(height)はバーの高さを整数に変換）\nha=\u0026lsquo;center\u0026rsquo;\n水平（x軸）の配置を中央に合わせます。\nva=\u0026lsquo;bottom\u0026rsquo;\n垂直（y軸）の配置を下に合わせます。\nしたがって、コードを実行すると以下のように出力されます。 ","date":"2024年1月5日","permalink":"/ja/posts/4/","section":"ブログ投稿","summary":"\u003cp\u003eこの記事は、Python内のmatplotlibライブラリを使用してグラフにテキストを追加する方法を説明するために作成されました。\u003c/p\u003e","title":"Python - Matplotlib テキスト追加"},{"content":"","date":null,"permalink":"/ja/tags/date_range/","section":"Tags","summary":"","title":"date_range"},{"content":"","date":null,"permalink":"/ja/tags/iloc/","section":"Tags","summary":"","title":"iloc"},{"content":"","date":null,"permalink":"/ja/tags/loc/","section":"Tags","summary":"","title":"loc"},{"content":"この投稿は、Pythonの pandas ライブラリを活用してDataFrameを扱う際に必要な**.loc()と.iloc()**のそれぞれの特徴と違いを説明するために作成されました。\nまず、説明のために seaborn を活用して例のデータ(iris)を取得しましょう。\n\u0026gt;\u0026gt;\u0026gt; import seaborn as sns \u0026gt;\u0026gt;\u0026gt; iris = sns.load_dataset(\u0026#39;iris\u0026#39;) \u0026gt;\u0026gt;\u0026gt; iris.head() irisデータの最初の5行 1. loc #locはラベル(Label)を基にデータを選択するメソッドです。行と列の名前を使用してデータにアクセスします。つまり、行と列の名前を明示的に指定してデータを選択します。\n# 列名が\u0026#39;species\u0026#39;で、その値が\u0026#39;virginica\u0026#39;であるデータを選択 \u0026gt;\u0026gt;\u0026gt; iris.loc[iris[\u0026#39;species\u0026#39;] == \u0026#39;virginica\u0026#39;] speciesの中で\u0026rsquo;virginica\u0026rsquo;の値を持つ最初の5行 2. iloc #ilocは整数(Integer)基準のインデックスを使用してデータを選択するメソッドです。行と列の整数の位置(インデックス)を利用してデータにアクセスします。つまり、データの位置を整数で明示して選択します。\n# 最初の行と2番目の列にあるデータを選択 \u0026gt;\u0026gt;\u0026gt; iris.iloc[0, 1] 3.5 最初の行と2番目の列にある\u0026rsquo;sepal_width\u0026rsquo;のデータ 3. locとilocの違い # インデックスのタイプ:\nlocはラベル(Label)を使用するため、行と列の名前が文字列や他のデータタイプである可能性があります。\nilocは整数(Integer)を使用するため、行と列のインデックスは整数である必要があります。\n使用方法:\nlocは明示的にラベルを使用してデータを選択することに重点を置きます。\nilocは整数位置(インデックス)を使用してデータを選択することに重点を置きます。\n例:\nlocの例: df.loc[\u0026lsquo;A\u0026rsquo;, \u0026lsquo;column_name\u0026rsquo;]\nilocの例: df.iloc[0, 1]\nどのメソッドを使用するかは、データフレームの構造やユーザーの目的によって異なります。 locはラベルが明確に定義されている場合に有用であり、 ilocは整数基準のインデックスが使用される場合に有用です。\n","date":"2024年1月4日","permalink":"/ja/posts/3/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は、Pythonの \u003cem\u003e\u003cstrong\u003epandas\u003c/strong\u003e\u003c/em\u003e ライブラリを活用してDataFrameを扱う際に必要な**.loc()と.iloc()**のそれぞれの特徴と違いを説明するために作成されました。\u003c/p\u003e","title":"Python - pandas loc vs iloc"},{"content":"この投稿は、pandasライブラリ内で日付を自動的に生成できるdate_range()関数について説明するために作成されました。\nデータのインデックスに日付を一つ一つ入力する代わりに、pandasのdate_range()を活用すると、値が多い時に便利です。\ndate_range()は以下のように使用します。\n\u0026gt;\u0026gt;\u0026gt; pd.date_range(start=\u0026#39;日付\u0026#39;, end=\u0026#39;日付\u0026#39;, freq=\u0026#39;周期\u0026#39;) 例を挙げて説明します。\n\u0026gt;\u0026gt;\u0026gt; pd.date_range(start=\u0026#39;2024/01/01\u0026#39;, end=\u0026#39;2024/01/07\u0026#39;) DatetimeIndex([\u0026#39;2024-01-01\u0026#39;, \u0026#39;2024-01-02\u0026#39;, \u0026#39;2024-01-03\u0026#39;, \u0026#39;2024-01-04\u0026#39;, \u0026#39;2024-01-05\u0026#39;, \u0026#39;2024-01-06\u0026#39;, \u0026#39;2024-01-07\u0026#39;], dtype=\u0026#39;datetime64[ns]\u0026#39;, freq=\u0026#39;D\u0026#39;) 出力された結果として、開始日である'2024/01/01\u0026rsquo;から終了日である'2024/01/07\u0026rsquo;までが出力されたことが確認できます。\nもう一つの例を見てみましょう。\n\u0026gt;\u0026gt;\u0026gt; pd.date_range(start=\u0026#39;2024-01-01 08:00\u0026#39;, periods = 4, freq = \u0026#39;H\u0026#39;) DatetimeIndex([\u0026#39;2024-01-01 08:00:00\u0026#39;, \u0026#39;2024-01-01 09:00:00\u0026#39;, \u0026#39;2024-01-01 10:00:00\u0026#39;, \u0026#39;2024-01-01 11:00:00\u0026#39;], dtype=\u0026#39;datetime64[ns]\u0026#39;, freq=\u0026#39;H\u0026#39;) 結果を見ると、開始日である'2024-01-01\u0026rsquo;の08時から周期である\u0026rsquo;H\u0026rsquo;（時間単位）を基にした4つの結果が出たことが確認できます。\nfreq（周期）を設定する場合、以下のリンク内のOffset aliasesを参照すると、様々な形で出力が可能です。\n参照: https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases\n","date":"2024年1月4日","permalink":"/ja/posts/2/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は、pandasライブラリ内で日付を自動的に生成できるdate_range()関数について説明するために作成されました。\u003c/p\u003e","title":"Python - pandasのdate_range"},{"content":"この投稿は、Pythonで値が連続しているデータタイプであるシーケンス(sequence types)について説明するために作成されました。\nシーケンスとは？ #シーケンス型(sequence types)とは、値が連続しているデータタイプを指します。 シーケンス型の最大の特徴は、共通の動作と機能を提供する点です。\nリスト [1, 2, 3, 4, 5] [1, 2, 3, 4, 5] タプル (1, 2, 3, 4, 5) (1, 2, 3, 4, 5) range range(5) 0, 1, 2, 3, 4 文字列 \u0026lsquo;Hello\u0026rsquo; H e l l o このように、シーケンスにはリスト、タプル、range、文字列があり、(bytes, bytearray)もこれに該当します。\nシーケンスで作成されたオブジェクトをシーケンスオブジェクトと呼び、各々の値を要素(element)と言います。\nシーケンスオブジェクト内の特定の値の確認 #シーケンスオブジェクト内に特定の値があるか確認するためには、以下のようにinまたはnot inを使用できます。\n\u0026gt;\u0026gt;\u0026gt; a = \u0026#34;Hello\u0026#34; \u0026gt;\u0026gt;\u0026gt; \u0026#34;H\u0026#34; in a True \u0026gt;\u0026gt;\u0026gt; \u0026#34;A\u0026#34; in a False # not in 特定の値がないか確認 \u0026gt;\u0026gt;\u0026gt; \u0026#34;ell\u0026#34; not in a False \u0026gt;\u0026gt;\u0026gt; \u0026#34;Python\u0026#34; not in a True in 演算子を使用した場合、特定の値があれば True、なければ Falseが返され、逆に not in 演算子を使用した場合、特定の値がなければ True、あれば Falseが返されます。\nシーケンスオブジェクトの連結 #シーケンスオブジェクトは + 演算子を使用して連結できます。\n\u0026gt;\u0026gt;\u0026gt; a = [0, 1, 2, 3] \u0026gt;\u0026gt;\u0026gt; b = [4, 5, 6] \u0026gt;\u0026gt;\u0026gt; a + b [0, 1, 2, 3, 4, 5, 6] ただし、 range는 + 演算子でオブジェクトを連結できません。\n\u0026gt;\u0026gt;\u0026gt; range(0, 5) + range(5, 10) TypeError Traceback (most recent call last) \u0026lt;ipython-input-7-88e74efcb3c0\u0026gt; in \u0026lt;cell line: 1\u0026gt;() ----\u0026gt; 1 range(0, 5) + range(5, 10) TypeError: unsupported operand type(s) for +: \u0026#39;range\u0026#39; and \u0026#39;range\u0026#39; したがって、rangeをタプルやリストに変換して連結することが可能です。\n\u0026gt;\u0026gt;\u0026gt; tuple(range(0, 5)) + tuple(range(5, 10)) (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) \u0026gt;\u0026gt;\u0026gt; list(range(0, 5)) + list(range(5, 10)) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] シーケンスオブジェクトの繰り返し #シーケンスオブジェクトは*演算子を使用して繰り返すことができます。 整数 * シーケンスオブジェクトまたはシーケンス * 整数で繰り返し可能です。\n\u0026gt;\u0026gt;\u0026gt; [0, 1, 2, 3] * 3 [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3] しかし、シーケンスオブジェクトの連結方法と同様に、rangesは * 演算子を使用して繰り返すことはできません。\n\u0026gt;\u0026gt;\u0026gt; range(0,10) * 3 TypeError Traceback (most recent call last) \u0026lt;ipython-input-11-824dcf3cff8f\u0026gt; in \u0026lt;cell line: 1\u0026gt;() ----\u0026gt; 1 range(0,10) * 3 TypeError: unsupported operand type(s) for *: \u0026#39;range\u0026#39; and \u0026#39;int\u0026#39; したがって、タプルやリストに変換して繰り返しは可能です。\nシーケンスオブジェクトの要素数の確認 #シーケンスオブジェクトの要素数は len 関数を使用して確認できます。\n# リスト \u0026gt;\u0026gt;\u0026gt; a = [1, 2, 3, 4, 5] \u0026gt;\u0026gt;\u0026gt; len(a) 5 # タプル \u0026gt;\u0026gt;\u0026gt; b = (6, 7, 8, 9, 10) \u0026gt;\u0026gt;\u0026gt; len(b) 5 # range len(range(0, 5, 2)) # -\u0026gt; 0から5まで2ずつ増やして 0, 2, 4 3 # 文字列 \u0026gt;\u0026gt;\u0026gt; c = \u0026#34;Hello, World\u0026#34; \u0026gt;\u0026gt;\u0026gt; len(c) 12 ","date":"2024年1月2日","permalink":"/ja/posts/1/","section":"ブログ投稿","summary":"\u003cp\u003eこの投稿は、Pythonで値が連続しているデータタイプであるシーケンス(sequence types)について説明するために作成されました。\u003c/p\u003e","title":"Python - シーケンス"},{"content":"","date":null,"permalink":"/ja/tags/sequence-types/","section":"Tags","summary":"","title":"sequence types"},{"content":"これは高度なタグです。Congoの他のリスティングページと同様に、個々のTaxonomy Termにカスタムコンテンツを追加することができ、Term Listの上部に表示されます。 🚀\nまた、これらのコンテンツページを使用して、SEOやその他の目的で使用されるタイトルや説明文などのHugoのメタデータを定義することもできます。\n","date":null,"permalink":"/ja/tags/advanced/","section":"Tags","summary":"これは高度なタグです。Congoの他のリスティングページと同様に、個々のTaxonomy Termにカスタムコンテンツを追加することができ、Term Listの上部に表示されます。 🚀","title":"advanced"},{"content":"","date":null,"permalink":"/ja/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"This section contains all my current projects.\n","date":null,"permalink":"/ja/projects/","section":"Projects","summary":"This section contains all my current projects.","title":"Projects"}]